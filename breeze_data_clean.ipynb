{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b96bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================\n",
    "# üõ† Enhanced Modular Data Collection\n",
    "# =====================================\n",
    "\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "# Import our enhanced utilities\n",
    "from app_config import Config\n",
    "from enhanced_breeze_utils import EnhancedBreezeDataManager, OptionChainAnalyzer\n",
    "from data_processing_utils import TechnicalIndicatorProcessor, OptionsDataProcessor\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# =====================================\n",
    "# üõ† Initialize Enhanced Data Manager\n",
    "# =====================================\n",
    "\n",
    "try:\n",
    "    # Initialize configuration and enhanced data manager\n",
    "    config = Config()\n",
    "    data_manager = EnhancedBreezeDataManager()\n",
    "    \n",
    "    # Initialize processing utilities\n",
    "    indicator_processor = TechnicalIndicatorProcessor()\n",
    "    options_processor = OptionsDataProcessor()\n",
    "    option_analyzer = OptionChainAnalyzer()\n",
    "    \n",
    "    # Set up Google Drive if in Colab environment\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "        logger.info(\"‚úÖ Google Drive mounted\")\n",
    "    except ImportError:\n",
    "        logger.info(\"‚ÑπÔ∏è Not in Colab environment, skipping Google Drive mount\")\n",
    "    \n",
    "    # Authenticate with enhanced retry logic\n",
    "    auth_result = data_manager.authenticate()\n",
    "    if auth_result.success:\n",
    "        logger.info(\"‚úÖ Breeze API authenticated successfully\")\n",
    "        breeze = data_manager.breeze\n",
    "    else:\n",
    "        logger.error(f\"‚ùå Authentication failed: {auth_result.error_message}\")\n",
    "        raise Exception(f\"Authentication failed: {auth_result.error_message}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    logger.error(f\"Critical initialization error: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "logger.info(\"‚úÖ All modules and enhanced utilities loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f0d4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================\n",
    "# üõ† Parameter Setup with Validation\n",
    "# =====================================\n",
    "\n",
    "from enhanced_breeze_utils import MarketDataRequest\n",
    "from data_processing_utils import ValidationError\n",
    "\n",
    "def setup_trading_parameters():\n",
    "    \"\"\"Setup and validate trading parameters with proper error handling\"\"\"\n",
    "    try:\n",
    "        # Basic parameters\n",
    "        stock_name = \"TCS\"\n",
    "        interval = \"5minute\"\n",
    "        \n",
    "        # Get trading dates using enhanced utilities\n",
    "        date_result = data_manager.get_trading_dates(days_back=30)\n",
    "        if not date_result.success:\n",
    "            raise ValidationError(f\"Failed to get trading dates: {date_result.error_message}\")\n",
    "        \n",
    "        from_date = date_result.data['from_date']\n",
    "        to_date = date_result.data['to_date']\n",
    "        \n",
    "        logger.info(f\"üìÖ Trading period: {from_date} to {to_date}\")\n",
    "        \n",
    "        # Get current LTP with enhanced error handling\n",
    "        ltp_result = data_manager.get_live_price(stock_name, \"NSE\")\n",
    "        if not ltp_result.success:\n",
    "            raise ValidationError(f\"Failed to get LTP: {ltp_result.error_message}\")\n",
    "        \n",
    "        ltp = ltp_result.data['ltp']\n",
    "        logger.info(f\"üì¶ Current LTP for {stock_name}: {ltp}\")\n",
    "        \n",
    "        # Get valid expiry using enhanced option analyzer\n",
    "        expiry_result = option_analyzer.get_next_valid_expiry(stock_name)\n",
    "        if not expiry_result.success:\n",
    "            raise ValidationError(f\"Failed to get expiry: {expiry_result.error_message}\")\n",
    "        \n",
    "        expiry_date = expiry_result.data['expiry_date']\n",
    "        logger.info(f\"üìå Using expiry: {expiry_date}\")\n",
    "        \n",
    "        # Create structured request object\n",
    "        request = MarketDataRequest(\n",
    "            stock_code=stock_name,\n",
    "            exchange_code=\"NSE\",\n",
    "            interval=interval,\n",
    "            from_date=from_date,\n",
    "            to_date=to_date,\n",
    "            expiry_date=expiry_date,\n",
    "            current_price=ltp\n",
    "        )\n",
    "        \n",
    "        return request\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Parameter setup failed: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Setup parameters\n",
    "market_request = setup_trading_parameters()\n",
    "logger.info(\"‚úÖ Parameters setup completed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f85f9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================\n",
    "# üìà Fetch Equity Data\n",
    "# =====================================\n",
    "\n",
    "def fetch_equity_data(request):\n",
    "    \"\"\"Fetch equity data with comprehensive error handling\"\"\"\n",
    "    try:\n",
    "        logger.info(f\"üìä Fetching equity data for {request.stock_code}\")\n",
    "        \n",
    "        # Use enhanced data manager for equity data\n",
    "        equity_result = data_manager.fetch_historical_data(\n",
    "            stock_code=request.stock_code,\n",
    "            exchange_code=request.exchange_code,\n",
    "            product_type=\"cash\",\n",
    "            interval=request.interval,\n",
    "            from_date=request.from_date,\n",
    "            to_date=request.to_date\n",
    "        )\n",
    "        \n",
    "        if not equity_result.success:\n",
    "            raise ValidationError(f\"Equity data fetch failed: {equity_result.error_message}\")\n",
    "        \n",
    "        equity_df = equity_result.data\n",
    "        \n",
    "        # Process with technical indicators using enhanced processor\n",
    "        processing_result = indicator_processor.process_dataframe(\n",
    "            equity_df,\n",
    "            add_all_indicators=True\n",
    "        )\n",
    "        \n",
    "        if not processing_result.success:\n",
    "            logger.warning(f\"Technical indicator processing had issues: {processing_result.error_message}\")\n",
    "            # Continue with raw data if indicator processing fails\n",
    "            processed_df = equity_df\n",
    "        else:\n",
    "            processed_df = processing_result.data\n",
    "        \n",
    "        # Save with metadata\n",
    "        save_result = data_manager.save_dataframe(\n",
    "            processed_df,\n",
    "            \"tcs_equity_data.csv\",\n",
    "            metadata={\n",
    "                \"source\": \"equity\",\n",
    "                \"stock_code\": request.stock_code,\n",
    "                \"interval\": request.interval,\n",
    "                \"indicators_count\": len([c for c in processed_df.columns if c not in ['datetime', 'open', 'high', 'low', 'close', 'volume']])\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        if save_result.success:\n",
    "            logger.info(f\"‚úÖ Equity data saved: {len(processed_df)} records with {len(processed_df.columns)} features\")\n",
    "        else:\n",
    "            logger.warning(f\"Save failed: {save_result.error_message}\")\n",
    "        \n",
    "        return processed_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Equity data fetch failed: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Fetch equity data\n",
    "equity_df = fetch_equity_data(market_request)\n",
    "logger.info(f\"üìà Equity data shape: {equity_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f923f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================\n",
    "# üìä Fetch Futures Data\n",
    "# =====================================\n",
    "\n",
    "def fetch_futures_data(request):\n",
    "    \"\"\"Fetch futures data with comprehensive error handling\"\"\"\n",
    "    try:\n",
    "        logger.info(f\"üìä Fetching futures data for {request.stock_code}\")\n",
    "        \n",
    "        # Use enhanced data manager for futures data\n",
    "        futures_result = data_manager.fetch_historical_data(\n",
    "            stock_code=request.stock_code,\n",
    "            exchange_code=\"NFO\",\n",
    "            product_type=\"futures\",\n",
    "            interval=request.interval,\n",
    "            from_date=request.from_date,\n",
    "            to_date=request.to_date,\n",
    "            expiry_date=request.expiry_date\n",
    "        )\n",
    "        \n",
    "        if not futures_result.success:\n",
    "            logger.warning(f\"Futures data fetch failed: {futures_result.error_message}\")\n",
    "            return None  # Return None instead of failing completely\n",
    "        \n",
    "        futures_df = futures_result.data\n",
    "        \n",
    "        # Process with technical indicators\n",
    "        processing_result = indicator_processor.process_dataframe(\n",
    "            futures_df,\n",
    "            add_all_indicators=True\n",
    "        )\n",
    "        \n",
    "        if not processing_result.success:\n",
    "            logger.warning(f\"Futures technical indicator processing failed: {processing_result.error_message}\")\n",
    "            processed_df = futures_df\n",
    "        else:\n",
    "            processed_df = processing_result.data\n",
    "        \n",
    "        # Save with metadata\n",
    "        save_result = data_manager.save_dataframe(\n",
    "            processed_df,\n",
    "            \"tcs_futures_data.csv\",\n",
    "            metadata={\n",
    "                \"source\": \"futures\",\n",
    "                \"stock_code\": request.stock_code,\n",
    "                \"expiry_date\": request.expiry_date,\n",
    "                \"interval\": request.interval\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        if save_result.success:\n",
    "            logger.info(f\"‚úÖ Futures data saved: {len(processed_df)} records\")\n",
    "        else:\n",
    "            logger.warning(f\"Futures save failed: {save_result.error_message}\")\n",
    "        \n",
    "        return processed_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Futures data processing error: {str(e)}\")\n",
    "        return None  # Graceful degradation\n",
    "\n",
    "# Fetch futures data\n",
    "futures_df = fetch_futures_data(market_request)\n",
    "if futures_df is not None:\n",
    "    logger.info(f\"üìä Futures data shape: {futures_df.shape}\")\n",
    "else:\n",
    "    logger.warning(\"‚ö†Ô∏è Futures data not available, continuing without it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c62ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================\n",
    "# üîÑ Fetch Options Data\n",
    "# =====================================\n",
    "\n",
    "def fetch_options_data(request):\n",
    "    \"\"\"Fetch comprehensive options data with enhanced error handling\"\"\"\n",
    "    try:\n",
    "        logger.info(f\"üîÑ Fetching options chain for {request.stock_code}\")\n",
    "        \n",
    "        # Use enhanced option analyzer for comprehensive chain data\n",
    "        chain_result = option_analyzer.fetch_full_option_chain(\n",
    "            stock_code=request.stock_code,\n",
    "            expiry_date=request.expiry_date,\n",
    "            current_price=request.current_price,\n",
    "            interval=request.interval,\n",
    "            from_date=request.from_date,\n",
    "            to_date=request.to_date,\n",
    "            strike_range=800  # Configurable range\n",
    "        )\n",
    "        \n",
    "        if not chain_result.success:\n",
    "            logger.warning(f\"Options chain fetch failed: {chain_result.error_message}\")\n",
    "            return None\n",
    "        \n",
    "        options_df = chain_result.data\n",
    "        \n",
    "        # Process options with specialized processor\n",
    "        processing_result = options_processor.process_options_dataframe(\n",
    "            options_df,\n",
    "            current_price=request.current_price,\n",
    "            add_greeks=True,\n",
    "            add_technical_indicators=True\n",
    "        )\n",
    "        \n",
    "        if not processing_result.success:\n",
    "            logger.warning(f\"Options processing failed: {processing_result.error_message}\")\n",
    "            processed_df = options_df\n",
    "        else:\n",
    "            processed_df = processing_result.data\n",
    "        \n",
    "        # Save with comprehensive metadata\n",
    "        save_result = data_manager.save_dataframe(\n",
    "            processed_df,\n",
    "            \"tcs_options_data.csv\",\n",
    "            metadata={\n",
    "                \"source\": \"options\",\n",
    "                \"stock_code\": request.stock_code,\n",
    "                \"expiry_date\": request.expiry_date,\n",
    "                \"current_price\": request.current_price,\n",
    "                \"strike_count\": len(processed_df['strike'].unique()) if 'strike' in processed_df.columns else 0,\n",
    "                \"total_records\": len(processed_df)\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        if save_result.success:\n",
    "            unique_strikes = len(processed_df['strike'].unique()) if 'strike' in processed_df.columns else 0\n",
    "            logger.info(f\"‚úÖ Options data saved: {len(processed_df)} records, {unique_strikes} strikes\")\n",
    "        else:\n",
    "            logger.warning(f\"Options save failed: {save_result.error_message}\")\n",
    "        \n",
    "        return processed_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Options data processing error: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Fetch options data\n",
    "options_df = fetch_options_data(market_request)\n",
    "if options_df is not None:\n",
    "    logger.info(f\"üîÑ Options data shape: {options_df.shape}\")\n",
    "else:\n",
    "    logger.warning(\"‚ö†Ô∏è Options data not available, continuing without it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe69aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================\n",
    "# üîó Data Combination and Enhancement\n",
    "# =====================================\n",
    "\n",
    "from data_processing_utils import ProcessingResult, DataQuality\n",
    "\n",
    "def combine_and_enhance_data(equity_df, futures_df=None, options_df=None):\n",
    "    \"\"\"Combine and enhance all datasets with comprehensive error handling\"\"\"\n",
    "    try:\n",
    "        logger.info(\"üîó Starting data combination and enhancement\")\n",
    "        \n",
    "        # Use enhanced options processor for data combination\n",
    "        combination_result = options_processor.combine_market_data(\n",
    "            equity_data=equity_df,\n",
    "            futures_data=futures_df,\n",
    "            options_data=options_df\n",
    "        )\n",
    "        \n",
    "        if not combination_result.success:\n",
    "            raise ValidationError(f\"Data combination failed: {combination_result.error_message}\")\n",
    "        \n",
    "        combined_df = combination_result.data\n",
    "        logger.info(f\"‚úÖ Data combined successfully: {combined_df.shape}\")\n",
    "        \n",
    "        # Enhance with relationship metadata using options processor\n",
    "        enhancement_result = options_processor.add_relationship_features(\n",
    "            combined_df,\n",
    "            include_correlations=True,\n",
    "            include_price_targets=True\n",
    "        )\n",
    "        \n",
    "        if not enhancement_result.success:\n",
    "            logger.warning(f\"Enhancement failed: {enhancement_result.error_message}\")\n",
    "            enhanced_df = combined_df\n",
    "        else:\n",
    "            enhanced_df = enhancement_result.data\n",
    "        \n",
    "        # Data quality assessment\n",
    "        quality_result = options_processor.assess_data_quality(enhanced_df)\n",
    "        logger.info(f\"üìä Data quality: {quality_result.metadata.get('quality_score', 'N/A')}\")\n",
    "        \n",
    "        # Save final enhanced dataset\n",
    "        save_result = data_manager.save_dataframe(\n",
    "            enhanced_df,\n",
    "            \"tcs_enhanced_data.csv\",\n",
    "            metadata={\n",
    "                \"source\": \"combined_enhanced\",\n",
    "                \"features_count\": len(enhanced_df.columns),\n",
    "                \"records_count\": len(enhanced_df),\n",
    "                \"data_quality\": quality_result.metadata.get('quality_score'),\n",
    "                \"processing_timestamp\": datetime.now().isoformat()\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        if save_result.success:\n",
    "            logger.info(f\"‚úÖ Enhanced dataset saved: {enhanced_df.shape} with {len(enhanced_df.columns)} features\")\n",
    "        else:\n",
    "            logger.warning(f\"Enhanced data save failed: {save_result.error_message}\")\n",
    "        \n",
    "        return enhanced_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Data combination and enhancement failed: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Combine and enhance all data\n",
    "try:\n",
    "    enhanced_df = combine_and_enhance_data(equity_df, futures_df, options_df)\n",
    "    \n",
    "    # Final data summary\n",
    "    logger.info(\"=\"*50)\n",
    "    logger.info(\"üìä FINAL DATA SUMMARY\")\n",
    "    logger.info(\"=\"*50)\n",
    "    logger.info(f\"üìà Total records: {len(enhanced_df):,}\")\n",
    "    logger.info(f\"üìä Total features: {len(enhanced_df.columns):,}\")\n",
    "    logger.info(f\"üìÖ Date range: {enhanced_df['datetime'].min()} to {enhanced_df['datetime'].max()}\")\n",
    "    \n",
    "    # Feature breakdown\n",
    "    equity_features = len([c for c in enhanced_df.columns if c.startswith('equity_')])\n",
    "    futures_features = len([c for c in enhanced_df.columns if c.startswith('futures_')])\n",
    "    options_features = len([c for c in enhanced_df.columns if c.startswith('options_')])\n",
    "    relationship_features = len([c for c in enhanced_df.columns if any(keyword in c for keyword in ['corr_', 'basis_', 'divergence', 'ratio'])])\n",
    "    \n",
    "    logger.info(f\"üìà Equity features: {equity_features}\")\n",
    "    logger.info(f\"üìä Futures features: {futures_features}\")\n",
    "    logger.info(f\"üîÑ Options features: {options_features}\")\n",
    "    logger.info(f\"üîó Relationship features: {relationship_features}\")\n",
    "    logger.info(\"=\"*50)\n",
    "    logger.info(\"‚úÖ‚úÖ‚úÖ ALL DATA PROCESSING COMPLETED SUCCESSFULLY!\")\n",
    "    logger.info(\"=\"*50)\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"‚ùå Critical error in data processing: {str(e)}\")\n",
    "    # Provide graceful fallback\n",
    "    if 'equity_df' in locals():\n",
    "        logger.info(\"üìà Falling back to equity data only\")\n",
    "        enhanced_df = equity_df\n",
    "    else:\n",
    "        logger.error(\"üí• Complete failure - no data available\")\n",
    "        raise"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
